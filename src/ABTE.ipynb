{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, '../dataset')\n",
    "import data_preparation\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "if not os.path.exists('../dataset/prepared'):\n",
    "    os.makedirs('../dataset/prepared')\n",
    "data_preparation.to_csv('../dataset/atepc/restaurants_test.csv', '../dataset/prepared/restaurants_test.csv',)\n",
    "data_preparation.to_csv('../dataset/atepc/restaurants_train.csv', '../dataset/prepared/restaurants_train.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "data = pd.read_csv('../dataset/prepared/restaurants_train.csv')\n",
    "data_test = pd.read_csv('../dataset/prepared/restaurants_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os,sys\n",
    "\n",
    "class ATEDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, tags, pols = self.df.iloc[idx, :3].values\n",
    "\n",
    "        tokens = tokens.replace(\"'\", \"\").strip(\"][\").split(', ')\n",
    "        tags = tags.strip('][').split(', ')\n",
    "        pols = pols.strip('][').split(', ')\n",
    "\n",
    "        bert_tokens = []\n",
    "        bert_tags = []\n",
    "        bert_pols = []\n",
    "        for i in range(len(tokens)):\n",
    "            t = self.tokenizer.tokenize(tokens[i])\n",
    "            bert_tokens += t\n",
    "            bert_tags += [int(tags[i])]*len(t)\n",
    "            bert_pols += [int(pols[i])]*len(t)\n",
    "        \n",
    "        bert_ids = self.tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "\n",
    "        ids_tensor = torch.tensor(bert_ids)\n",
    "        tags_tensor = torch.tensor(bert_tags)\n",
    "        pols_tensor = torch.tensor(bert_pols)\n",
    "        return bert_tokens, ids_tensor, tags_tensor, pols_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "class ATEBert(torch.nn.Module):\n",
    "    def __init__(self, pretrain_model):\n",
    "        super(ATEBert, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrain_model)\n",
    "        self.linear = torch.nn.Linear(self.bert.config.hidden_size, 3)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, ids_tensors, tags_tensors, masks_tensors):\n",
    "        bert_outputs= self.bert(input_ids=ids_tensors, attention_mask=masks_tensors, return_dict=False)\n",
    "        bert_outputs = bert_outputs[0]\n",
    "\n",
    "        linear_outputs = self.linear(bert_outputs)\n",
    "        if tags_tensors is not None:\n",
    "            tags_tensors = tags_tensors.view(-1)\n",
    "            linear_outputs = linear_outputs.view(-1,3)\n",
    "            loss = self.loss_fn(linear_outputs, tags_tensors)\n",
    "            return loss\n",
    "        else:\n",
    "            return linear_outputs\n",
    "\n",
    "class ATEModel ():\n",
    "    def __init__(self, tokenizer):\n",
    "        self.model = ATEBert('bert-base-uncased')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.trained = False\n",
    "\n",
    "    def padding(self, samples):\n",
    "        from torch.nn.utils.rnn import pad_sequence\n",
    "        ids_tensors = [s[1] for s in samples]\n",
    "        ids_tensors = pad_sequence(ids_tensors, batch_first=True)\n",
    "        print(ids_tensors)\n",
    "\n",
    "        tags_tensors = [s[2] for s in samples]\n",
    "        tags_tensors = pad_sequence(tags_tensors, batch_first=True)\n",
    "\n",
    "        pols_tensors = [s[3] for s in samples]\n",
    "        pols_tensors = pad_sequence(pols_tensors, batch_first=True)\n",
    "        \n",
    "        masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long)\n",
    "        masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1)\n",
    "        print(masks_tensors)\n",
    "    \n",
    "        return ids_tensors, tags_tensors, pols_tensors, masks_tensors\n",
    "\n",
    "    def load_model(self, model, path):\n",
    "        model.load_state_dict(torch.load(path), strict=False)\n",
    "        \n",
    "    def save_model(self, model, name):\n",
    "        torch.save(model.state_dict(), name)        \n",
    "                \n",
    "\n",
    "    def train(self, data, epochs, device, batch_size=32, lr=1e-5):\n",
    "\n",
    "        # dataset and loader\n",
    "        ds = ATEDataset(data, self.tokenizer)\n",
    "        loader = DataLoader(ds, batch_size=batch_size, shuffle=True, collate_fn=self.padding)\n",
    "        \n",
    "        self.model = self.model.to(device)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        all_data = len(loader)-1\n",
    "        for epoch in range(epochs):\n",
    "            finish_data = 0\n",
    "            self.losses = []\n",
    "            current_times = []\n",
    "\n",
    "            n_batches = int(len(data)/batch_size)\n",
    "            # batch = next(iter(loader))\n",
    "            # print (batch[0].shape, batch[1].shape, batch[2].shape, batch[3].shape)\n",
    "            for nb in range((n_batches)):\n",
    "                t0 = time.time()\n",
    "\n",
    "                ids_tensors, tags_tensors, _, masks_tensors = next(iter(loader))\n",
    "                ids_tensor = ids_tensors.to(device)\n",
    "                tags_tensor = tags_tensors.to(device)\n",
    "                masks_tensor = masks_tensors.to(device)\n",
    "                loss = self.model(ids_tensors=ids_tensor, tags_tensors=tags_tensor, masks_tensors=masks_tensor)\n",
    "                self.losses.append(loss.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                finish_data += 1\n",
    "                current_time = round(time.time() - t0,3)\n",
    "                current_times.append(current_time)\n",
    "                print(\"epoch: {}\\tbatch: {}/{}\\tloss: {}\\tbatch time: {}\\ttotal time: {}\"\\\n",
    "                    .format(epoch, finish_data, all_data, loss.item(), current_time, sum(current_times)))\n",
    "\n",
    "            self.save_model(self.model, 'model_lr{}_epochs{}_batch{}.pkl'.format(lr, epoch, batch_size))\n",
    "            self.trained = True\n",
    "\n",
    "    def history (self):\n",
    "        if self.trained:\n",
    "            return self.losses\n",
    "        else:\n",
    "            raise Exception('Model not trained')\n",
    "\n",
    "    def unpack_sequence(self, packed_sequence, mask):\n",
    "        unpacked_sequence = []\n",
    "        for i in range(len(packed_sequence)):\n",
    "            if mask[i] == 1:\n",
    "                unpacked_sequence.append(packed_sequence[i])\n",
    "    \n",
    "        return unpacked_sequence\n",
    "\n",
    "    def test(self, data, device='cpu', batch_size=256, lr=1e-4, epochs=2):\n",
    "\n",
    "        ds = ATEDataset(data, self.tokenizer)\n",
    "        loader = DataLoader(ds, shuffle=True,batch_size =len(data), collate_fn=self.padding)\n",
    "        pred = []\n",
    "        trueth = []\n",
    "        \n",
    "        tags_real = [t.strip('][').split(', ') for t in data['Tags']]\n",
    "        tags_real = [[int(i) for i in t] for t in tags_real]\n",
    "\n",
    "        ids, tags, pols, masks = next(iter(loader))\n",
    "        ids_tensors = ids.clone()\n",
    "        tags_tensors = tags.clone()\n",
    "        masks_tensors = masks.clone()\n",
    "        \n",
    "        # load model if exists\n",
    "        if os.path.exists('model_lr{}_epochs{}_batch{}.pkl'.format(lr, epochs, batch_size)):\n",
    "            self.load_model(self.model, 'model_lr{}_epochs{}_batch{}.pkl'.format(lr, epochs, batch_size))\n",
    "        if not self.trained and not os.path.exists('model_lr{}_epochs{}_batch{}.pkl'.format(lr, epochs, batch_size)):\n",
    "            raise Exception('model not trained and does not exist')\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = self.model(ids_tensors=ids_tensors, tags_tensors=None, masks_tensors=masks_tensors)\n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            pred += list([int(j)  for i in predictions for j in i ])\n",
    "            trueth += list([int(j) for i in tags_tensors for j in i ])\n",
    "        acc = np.mean(np.array(trueth) == np.array(pred))\n",
    "\n",
    "        predictions = [self.unpack_sequence(p,m) for p, m in zip(predictions, masks_tensors)]\n",
    "        # predictions = [int(p) for p in predictions[0]]\n",
    "        return acc, predictions, tags_real\n",
    "\n",
    "    def accuracy(self, data, device='cpu', batch_size=256, lr=1e-4, epochs=2):\n",
    "        a, p = self.test(data, device, batch_size, lr, epochs)\n",
    "        return a\n",
    "\n",
    "    def predict (self, data, device='cpu', batch_size=256, lr=1e-4, epochs=2):\n",
    "        t, p = self.test(data, device, batch_size, lr, epochs)\n",
    "        return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# from abte import ATEModel\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ATEModel(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2065, 2017, 1000,  ...,    0,    0,    0],\n",
      "        [1012,    0,    0,  ...,    0,    0,    0],\n",
      "        [2013, 1996, 2927,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [2018, 1037, 2307,  ...,    0,    0,    0],\n",
      "        [1996, 5869, 8490,  ...,    0,    0,    0],\n",
      "        [2307, 2833, 1010,  ...,    0,    0,    0]])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "a, pred, t = model.test(data_test[:100], batch_size=256, lr=1e-4, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data, batch_size=256, lr=1e-4, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-180-5b63f09d3dea>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.mean(np.array(pred).flatten() == np.array(t).flatten())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred = [[int(i) for i in pred[row]] for row in range(len(pred))]\n",
    "np.mean(np.array(pred).flatten() == np.array(t).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_to_word(sentence, predictions):\n",
    "    \"\"\"\n",
    "    predictions: list of tags\n",
    "    sentence: list of words\n",
    "    \"\"\"\n",
    "    terms = []\n",
    "    for i, word in enumerate(sentence):\n",
    "        if predictions[i] == 1:\n",
    "            terms.append(word)\n",
    "    return terms\n",
    "\n",
    "def tag_to_word_df(df, column_name, tags):\n",
    "    \"\"\"\n",
    "    predictions: list of tags\n",
    "    sentence: list of words\n",
    "    \"\"\"\n",
    "    terms_list = []\n",
    "    for i in range(len(df)):\n",
    "        sentence = df.iloc[i]['Tokens']\n",
    "        sentence = sentence.replace(\"'\", \"\").strip(\"][\").split(', ')\n",
    "        terms = tag_to_word(sentence, tags[i])\n",
    "        terms_list.append(terms)\n",
    "    df[column_name] = terms_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1], t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-408511863eda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_to_word_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gold terms'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_to_word_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred terms'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_tags'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-181-873125ef4e85>\u001b[0m in \u001b[0;36mtag_to_word_df\u001b[0;34m(df, column_name, tags)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"][\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_to_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mterms_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterms_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-181-873125ef4e85>\u001b[0m in \u001b[0;36mtag_to_word\u001b[0;34m(sentence, predictions)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mterms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tags_real = [t.strip('][').split(', ') for t in data_test['Tags'][:100]]\n",
    "tags_real = [[int(i) for i in t] for t in tags_real]\n",
    "pred_string = [''.join(str(i) for i in p) for p in pred]\n",
    "data_test = tag_to_word_df(data_test[:100], 'gold terms', tags_real)\n",
    "data_test = tag_to_word_df(data_test[:100], 'pred terms', pred)\n",
    "data_test['predicted_tags'] = pred_string\n",
    "acc = np.mean(np.array(tags_real).flatten() == np.array(pred).flatten())\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e47b1a34c05c1e3b83a62d7885c9d1b5ef8a0522d3be0182d0a008ec409b2b3d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
